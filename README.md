# Modern-AI-with-unsloth.ai1

# Modern-AI-with-unsloth.ai

A lightweight repo collecting Colab notebooks for modern fine-tuning and reinforcement learning workflows using **Unsloth** across popular open models.

---

## ðŸ“š Notebooks

- **Colab1 â€” Full Finetuning (SmolLM2)**
  - Notebook: `Colab1_Full_Finetuning_Unsloth_SmolLM2.ipynb`
  - Open in Colab: https://colab.research.google.com/drive/1YciZOXNEkNos_E5jd41UakMFrmF6yZ0H?usp=sharing

- **Colab2 â€” LoRA Finetuning (SmolLM2)**
  - Notebook: `Colab2_LoRA_Finetuning_Unsloth_SmolLM2.ipynb`
  - Open in Colab: https://colab.research.google.com/drive/1BUjSA-SJFGmvcPKfVkw7TE1yQubxvUrn?usp=sharing

- **Colab3 â€” GRPO (gpt-oss 20B)**
  - Notebook: `Colab3_gpt_oss_(20B)_GRPO.ipynb`
  - Open in Colab: https://colab.research.google.com/drive/1gc9J67RRwrbSuYImxEsUo1miwgZyyW1s?usp=sharing

- **Colab4 â€” Vision-Language GRPO (Qwen2.5 7B VL)**
  - Notebook: `Colab4_Qwen2_5_7B_VL_GRPO.ipynb`
  - Open in Colab: https://colab.research.google.com/drive/1LcZxTTNuZ1LVCehuk_gmj6qlv-Jc6t9t?usp=sharing

- **Colab5 â€” Continued Pretraining (Mistral 7B v0.3)**
  - Notebook: `https://colab.research.google.com/drive/13MdmkU55k-IlUujEGoHYNSc0XT3ieH7N?usp=sharing`
  - Open in Colab: https://colab.research.google.com/drive/REPLACE_WITH_YOUR_LINK

ðŸŽ¥ **YouTube walkthrough:** https://youtu.be/REPLACE_WITH_YOUR_VIDEO

---

## ðŸ—ºï¸ Repository files navigation

- `Colab1_Full_Finetuning_Unsloth_SmolLM2.ipynb`
- `Colab2_LoRA_Finetuning_Unsloth_SmolLM2.ipynb`
- `Colab3_gpt_oss_(20B)_GRPO.ipynb`
- `Colab4_Qwen2_5_7B_VL_GRPO.ipynb`
- `Colab5_Mistral_v0_3_(7B)_CPT.ipynb`
- `README.md`

---

## ðŸš€ Quick Start

1. Click any **Open in Colab** link above.
2. In Colab: **Runtime â†’ Change runtime type â†’ GPU (T4/A100 if available)**.
3. Run cells top-to-bottom; fill in any required paths/tokens inside the notebook.

> Tip: Mount Google Drive inside Colab if you want checkpoints to persist.

---

## ðŸ”§ Whatâ€™s inside

- **Unsloth adapters** for efficient finetuning (full & LoRA).
- **GRPO** examples for RL-style optimization.
- **Vision-Language** training with Qwen2.5-VL.
- **Continued pretraining** for domain adaptation.

---

## ðŸ“„ Notes

- Make sure to respect each modelâ€™s license and terms.
- GPU availability and session limits vary by Colab tier.
- Update links above if you make your Colabs public/private later.

---

## ðŸ™Œ Acknowledgments

Thanks to the open-source communities behind **Unsloth**, **SmolLM2**, **gpt-oss**, **Qwen2.5**, and **Mistral**.
